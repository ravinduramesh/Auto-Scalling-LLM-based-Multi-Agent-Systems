import json

import re
import nltk
from nltk.stem import WordNetLemmatizer

jsonFilePaths = [
    # autogen backup1
    "Existing-Solution/Responses/GPT-4o-backup1/autogen-auto-agent-selection.json",
    "Existing-Solution/Responses/GPT-4o-backup1/autogen-random-agent-selection.json",
    "Existing-Solution/Responses/GPT-4o-backup1/autogen-round-robin-agent-selection.json",
    # autogen backup2
    "Existing-Solution/Responses/GPT-4o-backup2/autogen-auto-agent-selection.json",
    "Existing-Solution/Responses/GPT-4o-backup2/autogen-random-agent-selection.json",
    "Existing-Solution/Responses/GPT-4o-backup2/autogen-round-robin-agent-selection.json",
    # autogen backup3
    "Existing-Solution/Responses/GPT-4o-backup3/autogen-auto-agent-selection.json",
    "Existing-Solution/Responses/GPT-4o-backup3/autogen-random-agent-selection.json",
    "Existing-Solution/Responses/GPT-4o-backup3/autogen-round-robin-agent-selection.json",
    # IAAG and DRTAG backup1
    "Novel-Approach/Responses/GPT-4o-backup1/dynamic-agent-creation-llm-selection.json",
    "Novel-Approach/Responses/GPT-4o-backup1/dynamic-agent-creation-random-selection.json",
    "Novel-Approach/Responses/GPT-4o-backup1/dynamic-agent-creation-round-robin-selection.json",
    "Novel-Approach/Responses/GPT-4o-backup1/initial-auto-creation-agent-llm-selection.json",
    "Novel-Approach/Responses/GPT-4o-backup1/initial-auto-creation-random-selection.json",
    "Novel-Approach/Responses/GPT-4o-backup1/initial-auto-creation-round-robin-selection.json",
    # IAAG and DRTAG backup2
    "Novel-Approach/Responses/GPT-4o-backup2/dynamic-agent-creation-llm-selection.json",
    "Novel-Approach/Responses/GPT-4o-backup2/dynamic-agent-creation-random-selection.json",
    "Novel-Approach/Responses/GPT-4o-backup2/dynamic-agent-creation-round-robin-selection.json",
    "Novel-Approach/Responses/GPT-4o-backup2/initial-auto-creation-agent-llm-selection.json",
    "Novel-Approach/Responses/GPT-4o-backup2/initial-auto-creation-random-selection.json",
    "Novel-Approach/Responses/GPT-4o-backup2/initial-auto-creation-round-robin-selection.json",
    # IAAG and DRTAG backup3
    "Novel-Approach/Responses/GPT-4o-backup3/dynamic-agent-creation-llm-selection.json",
    "Novel-Approach/Responses/GPT-4o-backup3/dynamic-agent-creation-random-selection.json",
    "Novel-Approach/Responses/GPT-4o-backup3/dynamic-agent-creation-round-robin-selection.json",
    "Novel-Approach/Responses/GPT-4o-backup3/initial-auto-creation-agent-llm-selection.json",
    "Novel-Approach/Responses/GPT-4o-backup3/initial-auto-creation-random-selection.json",
    "Novel-Approach/Responses/GPT-4o-backup3/initial-auto-creation-round-robin-selection.json",
]

stopwords = set(nltk.corpus.stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', ' ', text) # remove punctuation
    text = re.sub(r'\d+', '', text) # remove numbers
    text = ' '.join([word for word in text.split() if word not in stopwords])
    text = ' '.join([lemmatizer.lemmatize(word) for word in nltk.word_tokenize(text)])
    return text

vocab = {
    # Possible Illnesses
    "appendicitis", "gynecological", "kidney stone", "gastrointestinal", "colon cancer", "ileitis", "ovarian", "crohn disease", "colitis", "diverticulitis", "urinary tract", "musculoskeletal issue", "hernia",
    "cardiovascular", "gallbladder", "obstruction", "renal", "yersinia enterocolitica", "campylobacter jejuni", "ectopic pregnancy", "pelvic inflammatory", "endocrine disorder", "endometriosis", "inflammatory bowel",
    # Diagnostic Plans and Treatments 
    "clinical examination", "blood test", "stool test", "ct", "urinalysis", "ultrasound", "surgery", "antibiotic", "pain management", "manage pain", "pain relief", "physical examination", "pysical exam", "medical history", "nephrology",
    "endoscopic evaluation", "laparoscopy", "laparoscopic", "allergies", "anesthetic", "anesthesia", "pelvic exam", "neurological examination", "hormone level", "mri", "endoscopic evaluation", "probiotics", "urine",
    # Preventive Actions, Prior and Post Treatment Advice  
    "diet", "dietary", "hydrated", "hydration", "rest", "symptom diary", "stress", "breathing", "deepbreathing", "relaxation", "relax", "strenuous activity", "acupuncture", "allergy", "water", "diet", "heat", "fasting", "pain medication"
}

conversationScores = dict()

# Read data from the JSON file
for jsonFilePath in jsonFilePaths:
    with open(jsonFilePath, "r") as jsonFile:
        jsonData = json.load(jsonFile)

    initialAgents = {"Patient", "General-Ward-Doctor", "Nurse"}
    initialAgentsContent = ""
    autoGeneratedAgentsContent = ""

    for entry in jsonData:
        if entry["role"] in initialAgents:
            initialAgentsContent += entry["content"] + " "
            initialAgents.remove(entry["role"])
        else:
            autoGeneratedAgentsContent += entry["content"] + " "

    # Clean the text data and remove stopwords
    initialAgentsCleanedContent = clean_text(initialAgentsContent)
    autoGeneratedAgentsCleanedContent = clean_text(autoGeneratedAgentsContent)

    initialAgentsTermSet = set(initialAgentsCleanedContent.split())
    autoGeneratedAgentsTermSet = set(autoGeneratedAgentsCleanedContent.split())
    termsToScoreConversation = vocab.intersection(autoGeneratedAgentsTermSet - initialAgentsTermSet)

    filename = jsonFilePath.split("/")[-2] + '\n' + jsonFilePath.split("/")[-1]
    conversationScores[filename] = len(termsToScoreConversation)

# Plot a graph of conversation scores calculated using binary weighting for new knowledge
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
plt.bar(conversationScores.keys(), conversationScores.values())
plt.xticks(rotation=90)
plt.ylabel("Conversation Score")
plt.title("Conversation score calculated using binary weighting for new knowledge")
plt.tight_layout()
plt.savefig("conversation-scores-binary-weighting2.png")
print("Graph is plotted successfully.")